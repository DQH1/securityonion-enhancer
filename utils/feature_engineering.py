import pandas as pd
import numpy as np
import logging

# Set up logging
logger = logging.getLogger(__name__)

def engineer_enhanced_features(df: pd.DataFrame, top_services_list: list) -> pd.DataFrame:
    """
 
    
    Args:
        df: Input DataFrame (from conn.log) - should already have IP profiler features
        top_services_list: A pre-computed list of top services from the training data.

    Returns:
        DataFrame with engineered features (NO one-hot encoding).
    """
    logger.info("Engineering enhanced features...")
    df_features = df.copy()

    # 1. Enhanced history features
    df_features['hist_len'] = df_features['history'].astype(str).str.len()
    df_features['hist_R_count'] = df_features['history'].astype(str).str.count('[Rr]')
    df_features['hist_has_T'] = df_features['history'].astype(str).str.contains('[Tt]', na=False).astype(int)

    # 2. Advanced network behavior features
    failed_states = ['REJ', 'S0', 'RSTO', 'RSTR', 'RSTOS0', 'RSTRH', 'SH', 'SHR']
    df_features['is_failed_connection'] = df_features['conn_state'].isin(failed_states).astype(int)

    # Tunneling detection
    # Ensure 'tunnel_parents' column exists, if not, create it with a default value
    if 'tunnel_parents' not in df_features.columns:
        df_features['tunnel_parents'] = 'none'

    df_features['is_tunneled_connection'] = (
        df_features['tunnel_parents'].notna() &
        (df_features['tunnel_parents'] != '') &
        (df_features['tunnel_parents'] != '-') &
        (df_features['tunnel_parents'] != 'none')
    ).astype(int)

    # 3. Enhanced port and service binning - COLUMNTRANSFORMER WILL HANDLE ONE-HOT ENCODING
    def enhanced_port_binning(port):
        if pd.isna(port) or port == 0: return 'low'
        try:
            port = int(port)
            if port <= 1023: return 'low'           # Well-known ports
            elif port <= 49151: return 'medium'     # Registered ports
            elif port <= 65535: return 'high'       # Dynamic ports
            else: return 'very_high'                # Invalid ports
        except (ValueError, TypeError):
            return 'low'
    df_features['orig_port_binned'] = df_features['id.orig_p'].apply(enhanced_port_binning)
    df_features['resp_port_binned'] = df_features['id.resp_p'].apply(enhanced_port_binning)
    


    # Enhanced service binning - COLUMNTRANSFORMER WILL HANDLE ONE-HOT ENCODING
    def enhanced_service_binning(service):
        if pd.isna(service) or service in ['unknown', '-', '']: return 'rare'
        elif service in top_services_list[:5]: return 'common'      # Top 5 services
        elif service in top_services_list[5:15]: return 'uncommon'  # Next 10 services
        else: return 'rare'                                        # All others
    
    df_features['service_binned'] = df_features['service'].apply(enhanced_service_binning)
    

    required_stateful_features = [
        'concurrent_connections',
        'ip_profile_uid_rate',
        'ip_profile_id.resp_p_rate', 
        'ip_profile_id.resp_h_rate',
        'ip_profile_conn_state_diversity',
        'ip_profile_mean_duration',
        'ip_profile_mean_orig_bytes'

    ]
    
    missing_stateful_features = []
    for feature in required_stateful_features:
        if feature not in df_features.columns:
            missing_stateful_features.append(feature)
    
    if missing_stateful_features:
        logger.warning(f"⚠️  Missing stateful features from UnifiedIPProfiler: {missing_stateful_features}")
        logger.warning("   These features should be generated by UnifiedIPProfiler.process_connection_incremental() before calling engineer_features()")
        logger.warning("   Check if process_complete_record is preserving features correctly")
        

        raise ValueError(f"Missing stateful features: {missing_stateful_features}. UnifiedIPProfiler features must be preserved.")
    

    # Group features are now Z-score features produced by GroupFeatureTransformer
    expected_group_features = [
        'z_horizontal_unique_dst_ip_count', 'z_horizontal_problematic_ratio',
        'z_vertical_unique_dst_port_count', 'z_vertical_problematic_ratio',
        'z_beacon_group_count', 'z_ddos_group_unique_src_ip_count',
        'z_beacon_channel_timediff_std', 'z_beacon_channel_duration_std', 'z_beacon_channel_orig_bytes_std'
    ]
    
    logger.info("✅ Feature engineering complete.")
    logger.info(f"   Basic features: {len(df_features.columns)} columns")
    logger.info(f"   Stateful features validated: {len([f for f in required_stateful_features if f in df_features.columns])}/{len(required_stateful_features)}")
    logger.info(f"   Z-score group features will be added by GroupFeatureTransformer: {len(expected_group_features)} features")
    logger.info(f"   ✅ NO one-hot encoding here - ColumnTransformer will handle it")
    logger.info(f"   Categorical features ready for ColumnTransformer: orig_port_binned, resp_port_binned, service_binned")
    logger.info(f"   ✅ beacon_channel_* features now created by GroupFeatureTransformer (not here)")
    
    return df_features 